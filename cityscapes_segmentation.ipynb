{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b770d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import torch\n",
    "import pprint\n",
    "import pathlib\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import albumentations\n",
    "from tqdm import tqdm\n",
    "from models.hrnet import HRNet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from utils.transformations import re_normalize\n",
    "from utils.modelsummary import get_model_summary\n",
    "from utils.runners import train, validate, testval, testvideo\n",
    "from utils.data_utils import get_labels, label_mapping, SegmentationDataset, display\n",
    "from utils.train_utils import AverageMeter, CrossEntropy, get_confusion_matrix, create_logger\n",
    "from utils.transformation_pipelines import (get_transforms_training, get_transforms_validation, \n",
    "                                            get_transforms_evaluation, get_transforms_video)\n",
    "\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "labels = get_labels()\n",
    "id2label =      { label.id      : label for label in labels }\n",
    "trainid2label = { label.trainId : label for label in labels }\n",
    "\n",
    "def cityscapes_label_to_rgb(mask):\n",
    "    h = mask.shape[0]\n",
    "    w = mask.shape[1]\n",
    "    mask_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for key, val in trainid2label.items():\n",
    "        indices = mask == key\n",
    "        mask_rgb[indices.squeeze()] = val.color \n",
    "    return mask_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60a9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'cityscapes_dir': 'cityscapes',\n",
    "    'trainval_input_pattern': '*_leftImg8bit.png',\n",
    "    'trainval_annot_pattern': '*_gtFine_labelIds.png',\n",
    "    'trainval_image_dir': 'leftImg8bit',\n",
    "    'trainval_label_dir': 'gtFine',\n",
    "    \n",
    "    'DATASET': 'cityscapes',\n",
    "    'MODEL_NAME': 'seg_hrnet_w48',\n",
    "    'OUTPUT_DIR': 'outputs',\n",
    "    'LOG_DIR': 'logs',\n",
    "    \n",
    "    'CROP_SIZE': (512, 1024),\n",
    "    'BASE_SIZE': (1024, 2048),\n",
    "    'DATASET_MEAN': [0.485, 0.456, 0.406],\n",
    "    'DATASET_STD': [0.229, 0.224, 0.225],\n",
    "    'EPOCHS': 484,\n",
    "    'BATCH_SIZE': 12, \n",
    "    'NUM_CLASSES': 19,\n",
    "    'IGNORE_LABEL': 255,\n",
    "    'NUM_OUTPUTS': 1,\n",
    "    'BASE_LR': 1e-2,\n",
    "    'END_LR': 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967d2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_training = get_transforms_training(config)\n",
    "transforms_validation = get_transforms_validation(config)\n",
    "transforms_evaluation = get_transforms_evaluation(config)\n",
    "transforms_video = get_transforms_video(config)\n",
    "\n",
    "\n",
    "train_dataset = SegmentationDataset(config = config, split = \"train\", transform = transforms_training)\n",
    "valid_dataset = SegmentationDataset(config = config, split = \"val\", transform = transforms_validation)\n",
    "eval_dataset = SegmentationDataset(config = config, split = \"val\", transform = transforms_evaluation)\n",
    "video_dataset = SegmentationDataset(config = config, split = \"demoVideo\", transform = transforms_video, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d83b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (12, 3, 512, 1024), x.type: torch.float32, [min(x), max(x)]: [-2.118, 2.640]\n",
      "y.shape: (12, 512, 1024), y.type: torch.int64 \n",
      "y unique: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 255]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = config['BATCH_SIZE'], \n",
    "                              shuffle = True, num_workers = 4, prefetch_factor = 8,  pin_memory = False)\n",
    "\n",
    "valid_dataloader = DataLoader(dataset = valid_dataset, batch_size = config['BATCH_SIZE'], \n",
    "                              shuffle = True, num_workers = 4, prefetch_factor = 8,  pin_memory = False)\n",
    "\n",
    "eval_dataloader = DataLoader(dataset = eval_dataset, batch_size = 1, shuffle = False, num_workers = 4, \n",
    "                             prefetch_factor = 8,  pin_memory = False)\n",
    "\n",
    "video_dataloader = DataLoader(dataset = video_dataset, batch_size = 1, shuffle = False, num_workers = 4, \n",
    "                              prefetch_factor = 8,  pin_memory = False)\n",
    "config['DECAY_STEPS'] = len(train_dataloader)*config['EPOCHS']\n",
    "\n",
    "x, y, _, names = next(iter(train_dataloader))\n",
    "xv, yv, _, vnames = next(iter(valid_dataloader))\n",
    "xt, yt, _, tnames = next(iter(eval_dataloader))\n",
    "xvd, _, tnames = next(iter(video_dataloader))\n",
    "\n",
    "x_min, x_max = x.min(), x.max()\n",
    "print('x.shape: {}, x.type: {}, [min(x), max(x)]: [{:.3f}, {:.3f}]'.format(x.numpy().shape, x.dtype, x_min, x_max))\n",
    "print('y.shape: {}, y.type: {} \\ny unique: {}'.format(y.numpy().shape, y.dtype, np.unique(y.numpy()).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebb9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "# display([re_normalize(x[idx].permute(1,2,0).numpy()), cityscapes_label_to_rgb(y[idx])])\n",
    "# display([re_normalize(xv[idx].permute(1,2,0).numpy()), cityscapes_label_to_rgb(yv[idx])])\n",
    "# display([re_normalize(xt[idx].permute(1,2,0).numpy()), cityscapes_label_to_rgb(yt[idx])])\n",
    "# display([re_normalize(xvd[idx].permute(1,2,0).numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2672568",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = HRNet(\n",
    "    stage1_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 1,'BLOCK': 'BOTTLENECK','NUM_BLOCKS': [4]}, \n",
    "    stage2_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 2,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4]},\n",
    "    stage3_cfg = {'NUM_MODULES': 4,'NUM_BRANCHES': 3,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4]},\n",
    "    stage4_cfg = {'NUM_MODULES': 3,'NUM_BRANCHES': 4,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4, 4]},\n",
    "    n_classes = config['NUM_CLASSES'], \n",
    "    input_height = 512, \n",
    "    input_width = 1024, \n",
    "    W = 48,\n",
    ").to(device)\n",
    "\n",
    "criterion = CrossEntropy(\n",
    "    ignore_label=config['IGNORE_LABEL'], \n",
    "    weight=train_dataset.class_weights\n",
    ").cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=config['BASE_LR'], \n",
    "    momentum=0.9, \n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# model.init_weights(pretrained = \"weights/HRNet_W48_C_pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd91cba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HRNet': {'stage1_cfg': {'NUM_MODULES': 1, 'NUM_BRANCHES': 1, 'BLOCK': 'BOTTLENECK', 'NUM_BLOCKS': [4], 'NUM_CHANNELS': [64]}, 'stage2_cfg': {'NUM_MODULES': 1, 'NUM_BRANCHES': 2, 'BLOCK': 'BASIC', 'NUM_BLOCKS': [4, 4], 'NUM_CHANNELS': [48, 96]}, 'stage3_cfg': {'NUM_MODULES': 4, 'NUM_BRANCHES': 3, 'BLOCK': 'BASIC', 'NUM_BLOCKS': [4, 4, 4], 'NUM_CHANNELS': [48, 96, 192]}, 'stage4_cfg': {'NUM_MODULES': 3, 'NUM_BRANCHES': 4, 'BLOCK': 'BASIC', 'NUM_BLOCKS': [4, 4, 4, 4], 'NUM_CHANNELS': [48, 96, 192, 384]}, 'NUM_CLASSES': 19, 'inplanes': 64, 'input_height': 512, 'input_width': 1024, 'W': 48}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/hrnet_w48_best.pth\")) #, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d1c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_loop():\n",
    "    \n",
    "    logger, final_output_dir, tb_log_dir = create_logger(\n",
    "        config, \n",
    "        cfg_name=\"seg_hrnet_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484\", \n",
    "        phase='train'\n",
    "    )\n",
    "    \n",
    "    # dump_input = torch.rand((1, 3, 512, 1024))\n",
    "    # logger.info(get_model_summary(model.cuda(), dump_input.cuda()))\n",
    "\n",
    "    writer_dict = {\n",
    "        'writer': SummaryWriter(tb_log_dir),\n",
    "        'train_global_steps': 0,\n",
    "        'valid_global_steps': 0,\n",
    "    }\n",
    "\n",
    "    best_mIoU = 0\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "\n",
    "        train(\n",
    "            config=config, \n",
    "            dataloader=train_dataloader, \n",
    "            model=model, \n",
    "            loss_fn=criterion, \n",
    "            optimizer=optimizer, \n",
    "            epoch=epoch, \n",
    "            scaler=torch.cuda.amp.GradScaler(),\n",
    "            writer_dict=writer_dict\n",
    "        )\n",
    "\n",
    "        valid_loss, mean_IoU, IoU_array = validate(\n",
    "            config=config, \n",
    "            dataloader=valid_dataloader, \n",
    "            model=model,  \n",
    "            loss_fn=criterion,\n",
    "            writer_dict=writer_dict\n",
    "        )\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'best_mIoU': best_mIoU,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(final_output_dir,'checkpoint.pth.tar'))\n",
    "\n",
    "        if mean_IoU > best_mIoU:\n",
    "            best_mIoU = mean_IoU\n",
    "            torch.save(model.state_dict(), os.path.join(final_output_dir, 'best.pth'))\n",
    "\n",
    "        msg = 'Epoch {}/{}, Loss: {:.3f}, MeanIU: {: 4.4f}, Best_mIoU: {: 4.4f} \\n'.format(\n",
    "            epoch+1, config['EPOCHS'], valid_loss, mean_IoU, best_mIoU)\n",
    "        logging.info(msg)\n",
    "        \n",
    "    torch.save(model.state_dict(), os.path.join(final_output_dir, 'final_state.pth'))\n",
    "\n",
    "    writer_dict['writer'].close()\n",
    "    end = timeit.default_timer()\n",
    "    logger.info('Hours: %d' % np.int((end-start)/3600))\n",
    "    logger.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c37e450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval(config, eval_dataloader, model, sv_dir='outputs', sv_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean IoU: {:.3f}, mean Accuracy: {:.3f}, Pixel Accuracy: {:.3f}\".format(mean_IoU, mean_acc, pixel_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ff254",
   "metadata": {},
   "source": [
    "**Mean IoU**: 0.773\n",
    "\n",
    "**Mean Accuracy**: 0.854\n",
    "\n",
    "**Pixel Accuracy**: 0.960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in trainid2label.items():\n",
    "    if key != config['IGNORE_LABEL'] and key != -1:\n",
    "        print(\"{} --- IoU: {:.2f}\".format(val.name, IoU_array[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b87a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 2428/2899 [51:00<09:46,  1.24s/it]"
     ]
    }
   ],
   "source": [
    "testvideo(config, video_dataloader, model, sv_dir='outputs', sv_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a4cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
